{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bb892c",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8001a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 3969\n",
      "Test size 997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         medical_specialty                                      transcription  \\\n",
       "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
       "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
       "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"new_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"new_test.csv\", index_col=0)\n",
    "\n",
    "print(\"Train size\", len(train_df))\n",
    "print(\"Test size\", len(test_df))\n",
    "train_df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326d130",
   "metadata": {},
   "source": [
    "### Train Set Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c349df00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          863\n",
       " Consult - History and Phy.       410\n",
       " Cardiovascular / Pulmonary       309\n",
       " Orthopedic                       289\n",
       " Radiology                        213\n",
       " General Medicine                 209\n",
       " Gastroenterology                 176\n",
       " Neurology                        170\n",
       " SOAP / Chart / Progress Notes    135\n",
       " Urology                          134\n",
       " Obstetrics / Gynecology          123\n",
       " Discharge Summary                 87\n",
       " ENT - Otolaryngology              82\n",
       " Neurosurgery                      71\n",
       " Hematology - Oncology             68\n",
       " Ophthalmology                     67\n",
       " Emergency Room Reports            63\n",
       " Nephrology                        63\n",
       " Pediatrics - Neonatal             55\n",
       " Pain Management                   54\n",
       " Psychiatry / Psychology           45\n",
       " Office Notes                      38\n",
       " Podiatry                          35\n",
       " Dermatology                       21\n",
       " Dentistry                         21\n",
       " Cosmetic / Plastic Surgery        19\n",
       " Letters                           19\n",
       " Endocrinology                     16\n",
       " Physical Medicine - Rehab         16\n",
       " Bariatrics                        15\n",
       " IME-QME-Work Comp etc.            12\n",
       " Chiropractic                      12\n",
       " Sleep Medicine                    12\n",
       " Diets and Nutritions               9\n",
       " Speech - Language                  8\n",
       " Autopsy                            7\n",
       " Hospice - Palliative Care          6\n",
       " Allergy / Immunology               6\n",
       " Rheumatology                       6\n",
       " Lab Medicine - Pathology           5\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"medical_specialty\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8c8f3",
   "metadata": {},
   "source": [
    "### Sample Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4b315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('REASON FOR THE VISIT:,  Very high PT/INR.,HISTORY: , The patient is an '\n",
      " '81-year-old lady whom I met last month when she came in with pneumonia and '\n",
      " 'CHF.  She was noticed to be in atrial fibrillation, which is a chronic '\n",
      " 'problem for her.  She did not want to have Coumadin started because she said '\n",
      " 'that she has had it before and the INR has had been very difficult to '\n",
      " 'regulate to the point that it was dangerous, but I convinced her to restart '\n",
      " 'the Coumadin again.  I gave her the Coumadin as an outpatient and then the '\n",
      " 'INR was found to be 12.  So, I told her to come to the emergency room to get '\n",
      " 'vitamin K to reverse the anticoagulation.,PAST MEDICAL HISTORY:,1.  '\n",
      " 'Congestive heart failure.,2.  Renal insufficiency.,3.  Coronary artery '\n",
      " 'disease.,4.  Atrial fibrillation.,5.  COPD.,6.  Recent pneumonia.,7.  '\n",
      " 'Bladder cancer.,8.  History of ruptured colon.,9.  Myocardial '\n",
      " 'infarction.,10.  Hernia repair.,11.  Colon resection.,12.  Carpal tunnel '\n",
      " 'repair.,13.  Knee surgery.,MEDICATIONS:,1.  Coumadin.,2.  Simvastatin.,3.  '\n",
      " 'Nitrofurantoin.,4.  Celebrex.,5.  Digoxin.,6.  Levothyroxine.,7.  '\n",
      " 'Vicodin.,8.  Triamterene and hydrochlorothiazide.,9.  Carvedilol.,SOCIAL '\n",
      " 'HISTORY:  ,She does not smoke and she does not drink.,PHYSICAL '\n",
      " 'EXAMINATION:,GENERAL:  Lady in no distress.,VITAL SIGNS:  Blood pressure '\n",
      " '100/46, pulse of 75, respirations 12, and temperature 98.2.,HEENT:  Head is '\n",
      " 'normal.,NECK:  Supple.,LUNGS:  Clear to auscultation and percussion.,HEART:  '\n",
      " 'No S3, no S4, and no murmurs.,ABDOMEN:  Soft.,EXTREMITIES:  Lower '\n",
      " 'extremities, no edema.,ASSESSMENT:,1.  Atrial fibrillation.,2.  '\n",
      " 'Coagulopathy, induced by Coumadin.,PLAN: , Her INR at the office was 12.  I '\n",
      " 'will repeat it, and if it is still elevated, I will give vitamin K 10 mg in '\n",
      " '100 mL of D5W and then send her home and repeat the PT/INR next week.  I '\n",
      " 'believe at this time that it is too risky to use Coumadin in her case '\n",
      " 'because of her age and comorbidities, the multiple medications that she '\n",
      " 'takes and it is very difficult to keep an adequate level of anticoagulation '\n",
      " 'that is safe for her.  She is prone to a fall and this would be a big '\n",
      " 'problem.  We will use one aspirin a day instead of the anticoagulation.  She '\n",
      " 'is aware of the risk of stroke, but she is very scared of the '\n",
      " 'anticoagulation with Coumadin and does not want to use the Coumadin at this '\n",
      " 'time and I understand.  We will see her as an outpatient.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(train_df.transcription[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b6f4d",
   "metadata": {},
   "source": [
    "### Sample Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68977658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e142223",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = train_df[\"medical_specialty\"].unique()\n",
    "\n",
    "# idx_2_class = {i: s for i, s in enumerate(unique_classes)}\n",
    "# class_2_idx = {s: i for i, s in enumerate(unique_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac5d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"labels\"] = train_df[\"medical_specialty\"].apply(lambda s: class_2_idx[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56f3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(texts):\n",
    "    texts[\"transcription\"] = texts[\"transcription\"].apply(lambda x: re.sub(r\"[^a-zA-Z]+\", ' ', str(x)))\n",
    "\n",
    "    # change to lower case\n",
    "    texts[\"transcription\"] = texts[\"transcription\"].apply(lambda x: x.lower())\n",
    "\n",
    "    # tokenize texts\n",
    "    texts[\"transcription\"] = texts[\"transcription\"].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "    # pos tagging\n",
    "    texts[\"transcription\"] = texts[\"transcription\"].apply(lambda x: nltk.pos_tag(x))\n",
    "\n",
    "    # keep only nouns\n",
    "    texts[\"transcription\"] = texts[\"transcription\"].apply(lambda x: [t[0] for t in x if t[1].startswith('NN')])\n",
    "\n",
    "    # remove stop words\n",
    "    texts[\"transcription\"] = texts['transcription'].apply(lambda x : [word for word in x if word not in stop_words])\n",
    "\n",
    "    # join the tokens\n",
    "    texts['transcription'] = texts['transcription'].apply(lambda row: \" \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c6d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         medical_specialty                                      transcription  \\\n",
       "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
       "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
       "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>reason visit pt history patient year lady mont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>diagnosis fracture left column transverse post...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>name procedure angiography placement x mm xien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         medical_specialty                                      transcription  \\\n",
       "0   Emergency Room Reports  reason visit pt history patient year lady mont...   \n",
       "1                  Surgery  diagnosis fracture left column transverse post...   \n",
       "2                  Surgery  name procedure angiography placement x mm xien...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head(n=3))\n",
    "preprocess(train_df)\n",
    "preprocess(test_df)\n",
    "display(train_df.head(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233a4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_df, train_test_df = \\\n",
    "    train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449f16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {\n",
    "    'train': Dataset.from_pandas(train_train_df),\n",
    "    'val': Dataset.from_pandas(train_test_df),\n",
    "    \"test\": Dataset.from_pandas(test_df)\n",
    "}\n",
    "\n",
    "ds = DatasetDict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a995f402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80973a0d38134f239e591260fe516b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd306ecb98014cab9d8b8a0fc227e031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42e854a69d9441cb048f60691c17a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_text(texts):\n",
    "    return tokenizer(texts[\"transcription\"], truncation=True, padding=True, max_length=256)\n",
    "\n",
    "ds[\"train\"] = ds[\"train\"].map(tokenize_text, batched=True)\n",
    "ds[\"val\"] = ds[\"val\"].map(tokenize_text, batched=True)\n",
    "ds[\"test\"] = ds[\"test\"].map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa6c4319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25df8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ca876",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f26fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "414f5205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "logging_steps = len(train_train_df) // batch_size\n",
    "output_dir = \"hf_trainer\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "     num_train_epochs=10,\n",
    "     learning_rate=2e-4,\n",
    "     per_device_train_batch_size=batch_size,\n",
    "     per_device_eval_batch_size=batch_size,\n",
    "     weight_decay=0.01,\n",
    "     evaluation_strategy=\"epoch\",\n",
    "     logging_steps=logging_steps,\n",
    "     push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "994876be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8cfca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [870/870 05:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.305800</td>\n",
       "      <td>2.442997</td>\n",
       "      <td>0.044910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.114800</td>\n",
       "      <td>2.365844</td>\n",
       "      <td>0.053903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.009100</td>\n",
       "      <td>2.293385</td>\n",
       "      <td>0.072674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.897300</td>\n",
       "      <td>2.275804</td>\n",
       "      <td>0.065595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.756100</td>\n",
       "      <td>2.302154</td>\n",
       "      <td>0.083517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.656600</td>\n",
       "      <td>2.233137</td>\n",
       "      <td>0.085799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.547200</td>\n",
       "      <td>2.310744</td>\n",
       "      <td>0.084522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.447300</td>\n",
       "      <td>2.309730</td>\n",
       "      <td>0.088669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.357100</td>\n",
       "      <td>2.388913</td>\n",
       "      <td>0.092919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.244600</td>\n",
       "      <td>2.427491</td>\n",
       "      <td>0.087302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=870, training_loss=1.7283714119045215, metrics={'train_runtime': 336.9675, 'train_samples_per_second': 82.441, 'train_steps_per_second': 2.582, 'total_flos': 1841219072409600.0, 'train_loss': 1.7283714119045215, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6603a",
   "metadata": {},
   "source": [
    "### Making Inference on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3bc4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['transcription', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 997\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0d1f4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = trainer.predict(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0411c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(pred_y.predictions.argmax(axis=1))\n",
    "a.name = \"Expected\"\n",
    "a.to_csv(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
